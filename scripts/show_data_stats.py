#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯å±•ç¤ºå·¥å…·

åŠŸèƒ½:
1. æ˜¾ç¤ºæ€»ä½“æ•°æ®é‡
2. å„ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
3. å„æ‰¹æ¬¡ä¿¡æ¯
4. æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
5. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

ç”¨æ³•:
    python scripts/show_data_stats.py
    python scripts/show_data_stats.py --detailed
    python scripts/show_data_stats.py --export report.txt
"""

import os
import sys
import json
import argparse
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


class DataStatistics:
    """æ•°æ®ç»Ÿè®¡åˆ†æå™¨"""
    
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.data_dir = self.project_root / "data"
        self.stats_dir = self.data_dir / "statistics"
        self.yolo_dir = self.data_dir / "yolo_format"
        
        self.stats = {
            "overview": {},
            "classes": {},
            "batches": {},
            "splits": {}
        }
    
    def count_raw_images(self):
        """ç»Ÿè®¡åŸå§‹å›¾ç‰‡æ•°é‡"""
        raw_dir = self.data_dir / "raw"
        
        if not raw_dir.exists():
            return 0, {}
        
        total = 0
        batch_counts = {}
        
        # éå†æ‰¹æ¬¡ç›®å½•
        for batch_dir in raw_dir.iterdir():
            if batch_dir.is_dir() and batch_dir.name.startswith("batch_"):
                count = len(list(batch_dir.glob("*.png")))
                batch_counts[batch_dir.name] = count
                total += count
        
        # å¦‚æœæ²¡æœ‰æ‰¹æ¬¡ç›®å½•ï¼Œç›´æ¥ç»Ÿè®¡rawç›®å½•
        if not batch_counts:
            total = len(list(raw_dir.glob("*.png")))
            batch_counts["default"] = total
        
        return total, batch_counts
    
    def count_yolo_labels(self):
        """ç»Ÿè®¡YOLOæ ‡ç­¾æ–‡ä»¶å¹¶åˆ†æç±»åˆ«åˆ†å¸ƒ"""
        labels_dir = self.yolo_dir / "labels"
        
        if not labels_dir.exists():
            return {}, {}
        
        class_counts = defaultdict(int)
        split_counts = {"train": 0, "val": 0, "test": 0}
        
        # è¯»å–ç±»åˆ«åç§°
        config_file = self.yolo_dir / "dashboard.yaml"
        class_names = []
        if config_file.exists():
            import yaml
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                class_names = config.get('names', [])
        
        # ç»Ÿè®¡å„splitçš„æ ‡ç­¾
        for split in ["train", "val", "test"]:
            split_dir = labels_dir / split
            if split_dir.exists():
                label_files = list(split_dir.glob("*.txt"))
                split_counts[split] = len(label_files)
                
                # ç»Ÿè®¡ç±»åˆ«
                for label_file in label_files:
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if parts:
                                class_id = int(parts[0])
                                if class_id < len(class_names):
                                    class_counts[class_names[class_id]] += 1
                                else:
                                    class_counts[f"Unknown_{class_id}"] += 1
        
        return dict(class_counts), split_counts
    
    def load_batch_info(self):
        """åŠ è½½æ‰¹æ¬¡ä¿¡æ¯"""
        batch_file = self.stats_dir / "batch_info.json"
        
        if batch_file.exists():
            with open(batch_file, 'r', encoding='utf-8') as f:
                return json.load(f).get("batches", {})
        
        return {}
    
    def collect_stats(self):
        """æ”¶é›†æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š æ­£åœ¨æ”¶é›†æ•°æ®ç»Ÿè®¡ä¿¡æ¯...")
        
        # åŸå§‹å›¾ç‰‡ç»Ÿè®¡
        total_images, batch_counts = self.count_raw_images()
        self.stats["overview"]["total_raw_images"] = total_images
        self.stats["batches"] = {
            "counts": batch_counts,
            "total_batches": len(batch_counts)
        }
        
        # YOLOæ•°æ®ç»Ÿè®¡
        class_dist, split_dist = self.count_yolo_labels()
        self.stats["classes"] = class_dist
        self.stats["splits"] = split_dist
        self.stats["overview"]["total_yolo_labels"] = sum(split_dist.values())
        self.stats["overview"]["total_objects"] = sum(class_dist.values())
        
        # æ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯
        batch_info = self.load_batch_info()
        self.stats["batches"]["details"] = batch_info
        
        print("âœ… ç»Ÿè®¡å®Œæˆ\n")
    
    def print_overview(self):
        """æ‰“å°æ€»è§ˆ"""
        print("=" * 70)
        print("ğŸ“Š æ•°æ®é›†æ€»è§ˆ")
        print("=" * 70)
        
        overview = self.stats["overview"]
        print(f"\nğŸ“¦ åŸå§‹æ•°æ®:")
        print(f"   æ€»å›¾ç‰‡æ•°: {overview.get('total_raw_images', 0)} å¼ ")
        print(f"   æ€»æ‰¹æ¬¡æ•°: {self.stats['batches'].get('total_batches', 0)} ä¸ª")
        
        print(f"\nğŸ¯ è®­ç»ƒæ•°æ®:")
        print(f"   YOLOæ ‡ç­¾æ–‡ä»¶: {overview.get('total_yolo_labels', 0)} ä¸ª")
        print(f"   æ ‡æ³¨å¯¹è±¡æ€»æ•°: {overview.get('total_objects', 0)} ä¸ª")
        
        splits = self.stats["splits"]
        if sum(splits.values()) > 0:
            print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
            total = sum(splits.values())
            for split, count in splits.items():
                percentage = (count / total * 100) if total > 0 else 0
                print(f"   {split:6s}: {count:4d} ({percentage:5.1f}%)")
    
    def print_batches(self):
        """æ‰“å°æ‰¹æ¬¡ä¿¡æ¯"""
        print("\n" + "=" * 70)
        print("ğŸ“ æ‰¹æ¬¡ç»Ÿè®¡")
        print("=" * 70)
        
        batch_counts = self.stats["batches"].get("counts", {})
        batch_details = self.stats["batches"].get("details", {})
        
        if not batch_counts:
            print("\nâš ï¸  æœªæ‰¾åˆ°æ‰¹æ¬¡æ•°æ®")
            return
        
        print(f"\næ‰¹æ¬¡æ•°é‡: {len(batch_counts)}")
        print(f"\n{'æ‰¹æ¬¡ID':<15} {'å›¾ç‰‡æ•°':<10} {'æ·»åŠ æ—¥æœŸ':<12} {'IDèŒƒå›´'}")
        print("-" * 70)
        
        for batch_id in sorted(batch_counts.keys()):
            count = batch_counts[batch_id]
            details = batch_details.get(batch_id, {})
            date = details.get("date_added", "N/A")
            id_range = details.get("id_range", {})
            
            if id_range:
                range_str = f"{id_range.get('min', '?')} ~ {id_range.get('max', '?')}"
            else:
                range_str = "N/A"
            
            print(f"{batch_id:<15} {count:<10} {date:<12} {range_str}")
    
    def print_class_distribution(self, detailed=False):
        """æ‰“å°ç±»åˆ«åˆ†å¸ƒ"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡")
        print("=" * 70)
        
        class_dist = self.stats["classes"]
        
        if not class_dist:
            print("\nâš ï¸  æœªæ‰¾åˆ°ç±»åˆ«ç»Ÿè®¡æ•°æ®")
            return
        
        # æ’åºï¼ˆæŒ‰æ•°é‡é™åºï¼‰
        sorted_classes = sorted(class_dist.items(), key=lambda x: x[1], reverse=True)
        
        total = sum(class_dist.values())
        print(f"\næ€»æ ‡æ³¨å¯¹è±¡: {total} ä¸ª")
        print(f"ç±»åˆ«æ•°é‡: {len(class_dist)} ç§")
        
        print(f"\n{'ç±»åˆ«':<25} {'æ•°é‡':<8} {'å æ¯”':<8} {'ç­‰çº§'}")
        print("-" * 70)
        
        for class_name, count in sorted_classes:
            percentage = (count / total * 100) if total > 0 else 0
            
            # è¯„çº§
            if count >= 50:
                level = "âœ… å……è¶³"
            elif count >= 20:
                level = "ğŸŸ¡ é€‚ä¸­"
            elif count >= 10:
                level = "ğŸŸ  åå°‘"
            else:
                level = "ğŸ”´ ç´§ç¼º"
            
            print(f"{class_name:<25} {count:<8} {percentage:5.1f}%  {level}")
        
        if detailed:
            self.print_priority_analysis(sorted_classes)
    
    def print_priority_analysis(self, sorted_classes):
        """æ‰“å°ä¼˜å…ˆçº§åˆ†æ"""
        print("\n" + "=" * 70)
        print("ğŸ¯ æ•°æ®æ”¶é›†ä¼˜å…ˆçº§åˆ†æ")
        print("=" * 70)
        
        # åˆ†ç±»
        urgent = []      # <10
        important = []   # 10-20
        moderate = []    # 20-50
        sufficient = []  # >=50
        
        for class_name, count in sorted_classes:
            if count < 10:
                urgent.append((class_name, count))
            elif count < 20:
                important.append((class_name, count))
            elif count < 50:
                moderate.append((class_name, count))
            else:
                sufficient.append((class_name, count))
        
        if urgent:
            print(f"\nğŸ”´ ç´§æ€¥éœ€è¦ (æ ·æœ¬<10, å…±{len(urgent)}ç±»):")
            for name, count in urgent:
                target = max(30, count * 3)
                print(f"   - {name:<20} å½“å‰:{count:3d}ä¸ª  â†’  ç›®æ ‡:{target:3d}+ (éœ€+{target-count})")
        
        if important:
            print(f"\nğŸŸ¡ é‡è¦è¡¥å…… (æ ·æœ¬10-20, å…±{len(important)}ç±»):")
            for name, count in important:
                target = 40
                print(f"   - {name:<20} å½“å‰:{count:3d}ä¸ª  â†’  ç›®æ ‡:{target:3d}+ (éœ€+{target-count})")
        
        if moderate:
            print(f"\nğŸŸ¢ é€‚é‡å¢åŠ  (æ ·æœ¬20-50, å…±{len(moderate)}ç±»):")
            for name, count in moderate:
                print(f"   - {name:<20} å½“å‰:{count:3d}ä¸ª  â†’  ç»´æŒæˆ–å°å¹…å¢åŠ ")
        
        if sufficient:
            print(f"\nâœ… æ ·æœ¬å……è¶³ (æ ·æœ¬â‰¥50, å…±{len(sufficient)}ç±»):")
            print(f"   å¯ç»´æŒå½“å‰æ°´å¹³ï¼Œæ— éœ€ä¼˜å…ˆæ”¶é›†")
    
    def export_report(self, filepath):
        """å¯¼å‡ºç»Ÿè®¡æŠ¥å‘Š"""
        with open(filepath, 'w', encoding='utf-8') as f:
            # é‡å®šå‘printè¾“å‡º
            import contextlib
            
            @contextlib.contextmanager
            def redirect_stdout(fileobj):
                old_stdout = sys.stdout
                sys.stdout = fileobj
                try:
                    yield
                finally:
                    sys.stdout = old_stdout
            
            with redirect_stdout(f):
                f.write(f"æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"=" * 70 + "\n\n")
                
                self.print_overview()
                self.print_batches()
                self.print_class_distribution(detailed=True)
        
        print(f"\nâœ… æŠ¥å‘Šå·²å¯¼å‡º: {filepath}")
    
    def run(self, detailed=False, export=None):
        """è¿è¡Œç»Ÿè®¡åˆ†æ"""
        self.collect_stats()
        self.print_overview()
        self.print_batches()
        self.print_class_distribution(detailed=detailed)
        
        if export:
            self.export_report(export)
        
        print("\n" + "=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description="æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--detailed',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†çš„ä¼˜å…ˆçº§åˆ†æ'
    )
    
    parser.add_argument(
        '--export',
        type=str,
        metavar='FILE',
        help='å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆå¦‚: report.txtï¼‰'
    )
    
    args = parser.parse_args()
    
    stats = DataStatistics()
    stats.run(detailed=args.detailed, export=args.export)


if __name__ == "__main__":
    main()

