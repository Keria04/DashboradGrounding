#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»ªè¡¨ç›˜å›¾è¡¨æ£€æµ‹ä¸åˆ†å‰² - äº¤äº’å¼Demoåº”ç”¨
æ”¯æŒç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶æ ‡æ³¨å„ç§å›¾è¡¨ç±»å‹
"""

import os
import sys
from pathlib import Path
import cv2
import numpy as np
from ultralytics import YOLO
import argparse
from datetime import datetime

# è®¾ç½®UTF-8ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


class DashboardChartDetector:
    """ä»ªè¡¨ç›˜å›¾è¡¨æ£€æµ‹å™¨"""
    
    # é¢œè‰²æ˜ å°„ï¼ˆ20ç§ä¸åŒé¢œè‰²ç”¨äºä¸åŒå›¾è¡¨ç±»å‹ï¼‰
    COLORS = [
        (255, 0, 0),      # çº¢è‰²
        (0, 255, 0),      # ç»¿è‰²
        (0, 0, 255),      # è“è‰²
        (255, 255, 0),    # é»„è‰²
        (255, 0, 255),    # å“çº¢
        (0, 255, 255),    # é’è‰²
        (255, 128, 0),    # æ©™è‰²
        (128, 0, 255),    # ç´«è‰²
        (0, 255, 128),    # æ˜¥ç»¿
        (255, 0, 128),    # ç«ç‘°çº¢
        (128, 255, 0),    # é»„ç»¿
        (0, 128, 255),    # å¤©è“
        (255, 128, 128),  # æµ…çº¢
        (128, 255, 128),  # æµ…ç»¿
        (128, 128, 255),  # æµ…è“
        (255, 255, 128),  # æµ…é»„
        (255, 128, 255),  # æµ…å“çº¢
        (128, 255, 255),  # æµ…é’
        (192, 192, 192),  # é“¶è‰²
        (255, 165, 0),    # æ·±æ©™
    ]
    
    def __init__(self, model_path=None, conf_threshold=0.10, iou_threshold=0.4):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: NMSçš„IoUé˜ˆå€¼
        """
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # è‡ªåŠ¨æŸ¥æ‰¾æ¨¡å‹
        if model_path is None:
            model_path = self._find_best_model()
        
        if model_path is None or not Path(model_path).exists():
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼\n"
                f"è¯·å…ˆè®­ç»ƒæ¨¡å‹:\n"
                f"  python scripts/train_yolo_optimized.py\n"
                f"æˆ–æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹è·¯å¾„:\n"
                f"  python scripts/app_demo.py --model path/to/best.pt"
            )
        
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
        self.model = YOLO(model_path)
        self.model_path = Path(model_path)
        
        # è·å–ç±»åˆ«åç§°
        self.class_names = self.model.names
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼æ”¯æŒ {len(self.class_names)} ç§å›¾è¡¨ç±»å‹")
        print(f"   ç±»åˆ«: {list(self.class_names.values())[:5]}... (å…±{len(self.class_names)}ç§)")
        print()
    
    def _find_best_model(self):
        """è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹"""
        # ä¼˜å…ˆçº§é¡ºåº
        search_paths = [
            PROJECT_ROOT / "experiments" / "yolov8s_optimized" / "weights" / "best.pt",
            PROJECT_ROOT / "experiments" / "ultralytics_yolo" / "weights" / "best.pt",
            PROJECT_ROOT / "experiments" / "yolo_phase1_*" / "weights" / "best.pt",
        ]
        
        for pattern in search_paths:
            if '*' in str(pattern):
                # ä½¿ç”¨globæŸ¥æ‰¾
                matches = list(pattern.parent.parent.parent.glob(pattern.name))
                if matches:
                    # è¿”å›æœ€æ–°çš„
                    return max(matches, key=lambda p: p.stat().st_mtime)
            elif pattern.exists():
                return pattern
        
        return None
    
    def detect(self, image_path):
        """
        æ£€æµ‹å›¾åƒä¸­çš„å›¾è¡¨
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            results: æ£€æµ‹ç»“æœ
            annotated_image: æ ‡æ³¨åçš„å›¾åƒ
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        # æ‰§è¡Œæ£€æµ‹
        results = self.model.predict(
            image_path,
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            verbose=False
        )[0]
        
        # æ ‡æ³¨å›¾åƒ
        annotated_image = self._annotate_image(image.copy(), results)
        
        return results, annotated_image
    
    def _annotate_image(self, image, results):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾"""
        boxes = results.boxes
        
        if len(boxes) == 0:
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œæ·»åŠ æç¤º
            h, w = image.shape[:2]
            cv2.putText(
                image,
                "No charts detected!",
                (w // 2 - 150, h // 2),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                (0, 0, 255),
                2
            )
            return image
        
        # éå†æ¯ä¸ªæ£€æµ‹æ¡†
        for i, box in enumerate(boxes):
            # è·å–åæ ‡
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            
            # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
            cls_id = int(box.cls[0].cpu().numpy())
            conf = float(box.conf[0].cpu().numpy())
            class_name = self.class_names[cls_id]
            
            # é€‰æ‹©é¢œè‰²
            color = self.COLORS[cls_id % len(self.COLORS)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            label = f"{class_name}: {conf:.2f}"
            
            # è®¡ç®—æ ‡ç­¾èƒŒæ™¯å¤§å°
            (label_w, label_h), baseline = cv2.getTextSize(
                label,
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                2
            )
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(
                image,
                (x1, y1 - label_h - baseline - 5),
                (x1 + label_w, y1),
                color,
                -1
            )
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            cv2.putText(
                image,
                label,
                (x1, y1 - baseline - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2
            )
            
            # åœ¨æ¡†å†…æ·»åŠ åºå·
            cv2.putText(
                image,
                f"#{i+1}",
                (x1 + 5, y1 + 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                color,
                2
            )
        
        return image
    
    def print_detection_summary(self, results):
        """æ‰“å°æ£€æµ‹æ‘˜è¦"""
        boxes = results.boxes
        
        if len(boxes) == 0:
            print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•å›¾è¡¨")
            print()
            print("ğŸ’¡ å»ºè®®:")
            print("   - é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ (--conf 0.05)")
            print("   - æ£€æŸ¥å›¾åƒè´¨é‡")
            print("   - ç¡®ä¿å›¾åƒåŒ…å«æ”¯æŒçš„å›¾è¡¨ç±»å‹")
            return
        
        print(f"âœ… æ£€æµ‹åˆ° {len(boxes)} ä¸ªå›¾è¡¨:")
        print()
        
        # æŒ‰ç±»åˆ«åˆ†ç»„ç»Ÿè®¡
        class_counts = {}
        for box in boxes:
            cls_id = int(box.cls[0].cpu().numpy())
            class_name = self.class_names[cls_id]
            conf = float(box.conf[0].cpu().numpy())
            
            if class_name not in class_counts:
                class_counts[class_name] = {'count': 0, 'confs': []}
            class_counts[class_name]['count'] += 1
            class_counts[class_name]['confs'].append(conf)
        
        # æ‰“å°ç»Ÿè®¡
        for i, (class_name, info) in enumerate(sorted(
            class_counts.items(),
            key=lambda x: x[1]['count'],
            reverse=True
        ), 1):
            avg_conf = np.mean(info['confs'])
            print(f"  {i}. {class_name}: {info['count']}ä¸ª (å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.2%})")
        
        print()
    
    def save_results(self, image, output_path):
        """ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        cv2.imwrite(str(output_path), image)
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")
        print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.1f} KB")
        print()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä»ªè¡¨ç›˜å›¾è¡¨æ£€æµ‹ä¸åˆ†å‰² - äº¤äº’å¼Demo",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æ£€æµ‹å•å¼ å›¾ç‰‡
  python scripts/app_demo.py --image data/raw/dashboard_0001.png
  
  # æŒ‡å®šè¾“å‡ºè·¯å¾„
  python scripts/app_demo.py --image data/raw/dashboard_0001.png --output results/result.png
  
  # è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæé«˜å¬å›ç‡ï¼‰
  python scripts/app_demo.py --image data/raw/dashboard_0001.png --conf 0.05
  
  # ä½¿ç”¨æŒ‡å®šæ¨¡å‹
  python scripts/app_demo.py --image data/raw/dashboard_0001.png --model experiments/yolov8s_optimized/weights/best.pt
  
  # æ‰¹é‡å¤„ç†ï¼ˆå¤„ç†æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡ï¼‰
  python scripts/app_demo.py --image data/raw --output results
        """
    )
    
    parser.add_argument(
        '--image', '-i',
        type=str,
        required=True,
        help='è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼‰'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆé»˜è®¤: output/detection_ç»“æœ.pngï¼‰'
    )
    
    parser.add_argument(
        '--model', '-m',
        type=str,
        default=None,
        help='æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤: è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹ï¼‰'
    )
    
    parser.add_argument(
        '--conf',
        type=float,
        default=0.10,
        help='ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤: 0.10)'
    )
    
    parser.add_argument(
        '--iou',
        type=float,
        default=0.4,
        help='NMSçš„IoUé˜ˆå€¼ (é»˜è®¤: 0.4)'
    )
    
    parser.add_argument(
        '--show',
        action='store_true',
        help='æ˜¾ç¤ºç»“æœï¼ˆéœ€è¦GUIç¯å¢ƒï¼‰'
    )
    
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("=" * 70)
    print("ğŸ¯ ä»ªè¡¨ç›˜å›¾è¡¨æ£€æµ‹ä¸åˆ†å‰² - Phase 1 Demo")
    print("=" * 70)
    print()
    
    try:
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        detector = DashboardChartDetector(
            model_path=args.model,
            conf_threshold=args.conf,
            iou_threshold=args.iou
        )
        
        # å¤„ç†è¾“å…¥
        input_path = Path(args.image)
        
        if not input_path.exists():
            print(f"âŒ é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
            return
        
        # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
        if input_path.is_file():
            # å•æ–‡ä»¶å¤„ç†
            image_files = [input_path]
        else:
            # æ–‡ä»¶å¤¹å¤„ç†
            print(f"ğŸ“ æ‰«ææ–‡ä»¶å¤¹: {input_path}")
            image_files = []
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:
                image_files.extend(input_path.glob(ext))
            print(f"   æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
            print()
        
        if len(image_files) == 0:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        # å¤„ç†æ¯ä¸ªå›¾åƒ
        for i, image_file in enumerate(image_files, 1):
            print(f"{'=' * 70}")
            print(f"å¤„ç† [{i}/{len(image_files)}]: {image_file.name}")
            print(f"{'=' * 70}")
            print()
            
            # æ£€æµ‹
            results, annotated_image = detector.detect(image_file)
            
            # æ‰“å°æ‘˜è¦
            detector.print_detection_summary(results)
            
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if args.output:
                output_path = Path(args.output)
                if output_path.is_dir() or len(image_files) > 1:
                    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹æˆ–æ‰¹é‡å¤„ç†
                    output_path = output_path / f"detected_{image_file.stem}.png"
            else:
                # é»˜è®¤è¾“å‡ºè·¯å¾„
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = PROJECT_ROOT / "output" / f"detection_{image_file.stem}_{timestamp}.png"
            
            # ä¿å­˜ç»“æœ
            detector.save_results(annotated_image, output_path)
            
            # æ˜¾ç¤ºï¼ˆå¦‚æœéœ€è¦ï¼‰
            if args.show:
                cv2.imshow(f"Detection Result - {image_file.name}", annotated_image)
                cv2.waitKey(0)
                cv2.destroyAllWindows()
        
        print("=" * 70)
        print("âœ… æ‰€æœ‰å›¾åƒå¤„ç†å®Œæˆï¼")
        print("=" * 70)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

